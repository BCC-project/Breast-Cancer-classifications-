# -*- coding: utf-8 -*-
"""Minor Project BCC.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G9P9Nh9Dj4zC1i8v6KOGtA4OJnCBnMYr
"""

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

# Load the dataset
data = pd.read_csv('breast_cancer_data_cleaned.csv')

data.head(5)

data.shape

data.shape

data.isnull().sum()

data.info()

data.describe()

# Step 1: EDA
# Visualize the class distribution
sns.countplot(x='diagnosis', data=data)
plt.title('Distribution of Diagnosis (0 = Benign, 1 = Malignant)')
plt.show()

# Correlation matrix
plt.figure(figsize=(12, 10))
sns.heatmap(data.corr(), annot=False, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

# Step 2: Data Preprocessing
X = data.drop(columns=['diagnosis'])
y = data['diagnosis']

from imblearn.over_sampling import SMOTE

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Resample the training data using SMOTE
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

# Normalize the data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""log"""

from sklearn.utils.class_weight import compute_class_weight
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression

# Compute class weights
class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)
class_weights_dict = dict(zip(np.unique(y_train), class_weights))

# Initialize Logistic Regression with class weights
log_reg = LogisticRegression(class_weight=class_weights_dict, solver='liblinear', max_iter=200)

# Perform Grid Search for hyperparameter tuning
param_grid = {'C': [0.01, 0.1, 1, 10]}  # Regularization parameter
grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, cv=5, scoring='f1', n_jobs=-1)

# Train the model on resampled data
grid_search.fit(X_resampled, y_resampled)

# Retrieve the best model
best_model = grid_search.best_estimator_

# Predict using the best model
y_pred = best_model.predict(X_test)

# Compute evaluation metrics
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

print("Evaluation Metrics:")
print(f"Accuracy: {accuracy_score(y_test, y_pred):.4f}")
print(f"Precision: {precision_score(y_test, y_pred):.4f}")
print(f"Recall: {recall_score(y_test, y_pred):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred):.4f}")
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

"""knn"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV

# Initialize KNN
knn = KNeighborsClassifier()

# Hyperparameter tuning for KNN
param_grid_knn = {'n_neighbors': [3, 5, 7, 9, 11]}  # Tune the number of neighbors
grid_search_knn = GridSearchCV(estimator=knn, param_grid=param_grid_knn, cv=5, scoring='f1', n_jobs=-1)

# Train KNN using the resampled dataset
grid_search_knn.fit(X_resampled, y_resampled)

# Best KNN model
best_knn = grid_search_knn.best_estimator_

# Predictions and evaluation
y_pred_knn = best_knn.predict(X_test)

print("KNN Evaluation Metrics:")
print(f"Accuracy: {accuracy_score(y_test, y_pred_knn):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_knn):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_knn):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_knn):.4f}")
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_knn))

"""rf"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV

# Initialize Random Forest
rf = RandomForestClassifier(class_weight='balanced', random_state=42)

# Hyperparameter tuning for Random Forest
param_grid_rf = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10]
}
grid_search_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, cv=5, scoring='f1', n_jobs=-1)

# Train Random Forest using the resampled dataset
grid_search_rf.fit(X_resampled, y_resampled)

# Best Random Forest model
best_rf = grid_search_rf.best_estimator_

# Predictions and evaluation
y_pred_rf = best_rf.predict(X_test)

print("Random Forest Evaluation Metrics:")
print(f"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_rf):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_rf):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_rf):.4f}")
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_rf))

"""svm

"""

from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV

# Initialize SVM
svc = SVC(class_weight='balanced', probability=True, random_state=42)

# Hyperparameter tuning for SVM
param_grid_svm = {
    'C': [0.1, 1, 10],
    'gamma': [1, 0.1, 0.01],
    'kernel': ['rbf', 'linear']
}
grid_search_svm = GridSearchCV(estimator=svc, param_grid=param_grid_svm, cv=5, scoring='f1', n_jobs=-1)

# Train SVM using the resampled dataset
grid_search_svm.fit(X_resampled, y_resampled)

# Best SVM model
best_svm = grid_search_svm.best_estimator_

# Predictions and evaluation
y_pred_svm = best_svm.predict(X_test)

print("SVM Evaluation Metrics:")
print(f"Accuracy: {accuracy_score(y_test, y_pred_svm):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_svm):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_svm):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_svm):.4f}")
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_svm))

"""plotting curves"""

# Common imports
from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Function to plot the ROC curve
def plot_roc_curve(y_test, y_pred_proba, model_name):
    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
    roc_auc = roc_auc_score(y_test, y_pred_proba)

    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='gray', linestyle='--', label='Random Guess')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(f'ROC Curve for {model_name}')
    plt.legend(loc='lower right')
    plt.grid(True)
    plt.show()

# Function to plot the confusion matrix
def plot_confusion_matrix(y_test, y_pred, model_name):
    cm = confusion_matrix(y_test, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Benign", "Malignant"])
    disp.plot(cmap='Blues', values_format='d')
    plt.title(f'Confusion Matrix for {model_name}')
    plt.show()

"""log"""

# Logistic Regression Predictions
y_pred_proba_lr = best_model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class
plot_roc_curve(y_test, y_pred_proba_lr, "Logistic Regression")
plot_confusion_matrix(y_test, y_pred, "Logistic Regression")

"""knn"""

# KNN Predictions
y_pred_proba_knn = best_knn.predict_proba(X_test)[:, 1]  # Probabilities for the positive class
plot_roc_curve(y_test, y_pred_proba_knn, "K-Nearest Neighbors")
plot_confusion_matrix(y_test, y_pred_knn, "K-Nearest Neighbors")

"""rf"""

# Random Forest Predictions
y_pred_proba_rf = best_rf.predict_proba(X_test)[:, 1]  # Probabilities for the positive class
plot_roc_curve(y_test, y_pred_proba_rf, "Random Forest")
plot_confusion_matrix(y_test, y_pred_rf, "Random Forest")

"""svm"""

# SVM Predictions
y_pred_proba_svm = best_svm.predict_proba(X_test)[:, 1]  # Probabilities for the positive class
plot_roc_curve(y_test, y_pred_proba_svm, "Support Vector Machine")
plot_confusion_matrix(y_test, y_pred_svm, "Support Vector Machine")

"""Plotting a Histogram of Accuracies"""

import numpy as np

# Store accuracy scores for each model
accuracy_scores = {
    "Logistic Regression": accuracy_score(y_test, y_pred),
    "K-Nearest Neighbors": accuracy_score(y_test, y_pred_knn),
    "Random Forest": accuracy_score(y_test, y_pred_rf),
    "Support Vector Machine": accuracy_score(y_test, y_pred_svm),
}

# Plot histogram
plt.figure(figsize=(8, 6))
plt.bar(accuracy_scores.keys(), accuracy_scores.values(), color=['blue', 'green', 'orange', 'red'])
plt.xlabel('Models')
plt.ylabel('Accuracy')
plt.title('Model Accuracy Comparison')
plt.ylim(0, 1)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

"""Comparing ROC Curves on a Single Graph"""

# Generate ROC Curve data for all models
fpr_lr, tpr_lr, _ = roc_curve(y_test, best_model.predict_proba(X_test)[:, 1])
fpr_knn, tpr_knn, _ = roc_curve(y_test, best_knn.predict_proba(X_test)[:, 1])
fpr_rf, tpr_rf, _ = roc_curve(y_test, best_rf.predict_proba(X_test)[:, 1])
fpr_svm, tpr_svm, _ = roc_curve(y_test, best_svm.predict_proba(X_test)[:, 1])

# Calculate AUC for each model
auc_lr = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])
auc_knn = roc_auc_score(y_test, best_knn.predict_proba(X_test)[:, 1])
auc_rf = roc_auc_score(y_test, best_rf.predict_proba(X_test)[:, 1])
auc_svm = roc_auc_score(y_test, best_svm.predict_proba(X_test)[:, 1])

# Plot all ROC curves
plt.figure(figsize=(10, 8))
plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {auc_lr:.2f})', color='blue')
plt.plot(fpr_knn, tpr_knn, label=f'K-Nearest Neighbors (AUC = {auc_knn:.2f})', color='green')
plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {auc_rf:.2f})', color='orange')
plt.plot(fpr_svm, tpr_svm, label=f'SVM (AUC = {auc_svm:.2f})', color='red')
plt.plot([0, 1], [0, 1], 'k--', label='Random Guess', color='gray')

# Formatting the plot
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve Comparison')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

"""Code to Find the Best Model"""

# Step 1: Compare accuracy scores
accuracy_scores = {
    "Logistic Regression": accuracy_score(y_test, y_pred),
    "K-Nearest Neighbors": accuracy_score(y_test, y_pred_knn),
    "Random Forest": accuracy_score(y_test, y_pred_rf),
    "Support Vector Machine": accuracy_score(y_test, y_pred_svm),
}

# Step 2: Compare AUC scores
auc_scores = {
    "Logistic Regression": roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1]),
    "K-Nearest Neighbors": roc_auc_score(y_test, best_knn.predict_proba(X_test)[:, 1]),
    "Random Forest": roc_auc_score(y_test, best_rf.predict_proba(X_test)[:, 1]),
    "Support Vector Machine": roc_auc_score(y_test, best_svm.predict_proba(X_test)[:, 1]),
}

# Step 3: Find the best model based on accuracy and AUC
best_accuracy_model = max(accuracy_scores, key=accuracy_scores.get)
best_auc_model = max(auc_scores, key=auc_scores.get)

# Step 4: Print the results
print("Best Model Based on Accuracy:")
print(f"{best_accuracy_model} with Accuracy: {accuracy_scores[best_accuracy_model]:.4f}")
print("\nBest Model Based on AUC:")
print(f"{best_auc_model} with AUC: {auc_scores[best_auc_model]:.4f}")

# Step 5: Find the overall best model
if best_accuracy_model == best_auc_model:
    print("\nThe best model is the same based on both Accuracy and AUC:", best_accuracy_model)
else:
    print("\nThe best model based on Accuracy is:", best_accuracy_model)
    print("The best model based on AUC is:", best_auc_model)

"""Save the Model"""

import pickle

# Save the trained model to a file
with open('svm_model.pkl', 'wb') as f:
    pickle.dump(best_svm, f)  # 'best_svm' is your trained model

"""Load the Model"""

# Load the saved model from the file
with open('svm_model.pkl', 'rb') as f:
    loaded_svm_model = pickle.load(f)
print("Model loaded successfully")

"""building a predicted model"""

import pickle
import numpy as np
from google.colab import files

# Step 1: Upload the model file
uploaded = files.upload()

# Step 2: Load the SVM model from the .pkl file
with open('svm_model.pkl', 'rb') as f:
    loaded_svm_model = pickle.load(f)

# Step 3: Define your input data (make sure it has the same structure as the training data)
input_data = (18.61,20.25,122.1,1094.0,0.0944,0.1066,0.149,0.07731,0.1697,0.05699,0.8529,1.849,5.632,93.54,0.01075,0.02722,0.05081,0.01911,0.02293,0.004217,21.31,27.26,139.9,1403.0,0.1338,0.2117,0.3446,0.149,0.2341,0.07421
)

# Step 4: Convert the input data into a NumPy array and reshape for prediction
input_data_as_numpy_array = np.asarray(input_data)
input_data_reshaped = input_data_as_numpy_array.reshape(1, -1)

# Step 5: If you used any preprocessing (like scaling), apply it here:
# Example: if you used StandardScaler during training, you must scale the input data the same way:
# input_data_scaled = scaler.transform(input_data_reshaped)

# Step 6: Make prediction using the loaded model
prediction = loaded_svm_model.predict(input_data_reshaped)

# Step 7: Output the prediction result
if prediction[0] == 1:
    print("The Breast Cancer is Malignant")
else:
    print("The Breast Cancer is Benign")

